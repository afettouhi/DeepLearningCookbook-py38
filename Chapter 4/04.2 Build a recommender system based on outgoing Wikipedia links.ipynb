{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Reshape\n",
    "from keras.layers.merge import Dot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/wp_movies_10k.ndjson') as fin:\n",
    "    movies = [json.loads(l) for l in fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('Rotten Tomatoes', 9393),\n ('Category:English-language films', 5882),\n ('Category:American films', 5867),\n ('Variety (magazine)', 5450),\n ('Metacritic', 5112),\n ('Box Office Mojo', 4186),\n ('The New York Times', 3818),\n ('The Hollywood Reporter', 3553),\n ('Roger Ebert', 2707),\n ('Los Angeles Times', 2454)]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_counts = Counter()\n",
    "for movie in movies:\n",
    "    link_counts.update(movie[2])\n",
    "link_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(949544, 66913, 10000)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_links = [link for link, c in link_counts.items() if c >= 3]\n",
    "link_to_idx = {link: idx for idx, link in enumerate(top_links)}\n",
    "movie_to_idx = {movie[0]: idx for idx, movie in enumerate(movies)}\n",
    "pairs = []\n",
    "for movie in movies:\n",
    "    pairs.extend((link_to_idx[link], movie_to_idx[movie[0]]) for link in movie[2] if link in link_to_idx)\n",
    "pairs_set = set(pairs)\n",
    "len(pairs), len(top_links), len(movie_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "link (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "link_embedding (Embedding)      (None, 1, 50)        3345650     link[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "movie_embedding (Embedding)     (None, 1, 50)        500000      movie[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1, 1)         0           link_embedding[0][0]             \n",
      "                                                                 movie_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1)            0           dot_product[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,845,650\n",
      "Trainable params: 3,845,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def movie_embedding_model(embedding_size=50):\n",
    "    link = Input(name='link', shape=(1,))\n",
    "    movie = Input(name='movie', shape=(1,))\n",
    "    link_embedding = Embedding(name='link_embedding', \n",
    "                               input_dim=len(top_links), \n",
    "                               output_dim=embedding_size)(link)\n",
    "    movie_embedding = Embedding(name='movie_embedding', \n",
    "                                input_dim=len(movie_to_idx), \n",
    "                                output_dim=embedding_size)(movie)\n",
    "    dot = Dot(name='dot_product', normalize=True, axes=2)([link_embedding, movie_embedding])\n",
    "    merged = Reshape((1,))(dot)\n",
    "    model = Model(inputs=[link, movie], outputs=[merged])\n",
    "    model.compile(optimizer='nadam', loss='mse')\n",
    "    return model\n",
    "\n",
    "model = movie_embedding_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "({'link': array([13365., 22418.,  1313.,  3801., 20558., 32643., 48731., 32318.,\n         31254.]),\n  'movie': array([6238., 1529., 7236., 5874.,  849., 7628., 1854., 7685., 5530.])},\n array([-1.,  1.,  1., -1., -1., -1., -1., -1.,  1.]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(5)\n",
    "\n",
    "def batchifier(pairs, positive_samples=50, negative_ratio=10):\n",
    "    batch_size = positive_samples * (1 + negative_ratio)\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    while True:\n",
    "        for idx, (link_id, movie_id) in enumerate(random.sample(pairs, positive_samples)):\n",
    "            batch[idx, :] = (link_id, movie_id, 1)\n",
    "        idx = positive_samples\n",
    "        while idx < batch_size:\n",
    "            movie_id = random.randrange(len(movie_to_idx))\n",
    "            link_id = random.randrange(len(top_links))\n",
    "            if not (link_id, movie_id) in pairs_set:\n",
    "                batch[idx, :] = (link_id, movie_id, -1)\n",
    "                idx += 1\n",
    "        np.random.shuffle(batch)\n",
    "        yield {'link': batch[:, 0], 'movie': batch[:, 1]}, batch[:, 2]\n",
    "\n",
    "next(batchifier(pairs, positive_samples=3, negative_ratio=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-26ec9dad4de0>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "1854/1854 - 36s - loss: 0.5316\n",
      "Epoch 2/15\n",
      "1854/1854 - 36s - loss: 0.2324\n",
      "Epoch 3/15\n",
      "1854/1854 - 36s - loss: 0.2215\n",
      "Epoch 4/15\n",
      "1854/1854 - 36s - loss: 0.2179\n",
      "Epoch 5/15\n",
      "1854/1854 - 36s - loss: 0.2159\n",
      "Epoch 6/15\n",
      "1854/1854 - 36s - loss: 0.2147\n",
      "Epoch 7/15\n",
      "1854/1854 - 35s - loss: 0.2140\n",
      "Epoch 8/15\n",
      "1854/1854 - 35s - loss: 0.2134\n",
      "Epoch 9/15\n",
      "1854/1854 - 35s - loss: 0.2131\n",
      "Epoch 10/15\n",
      "1854/1854 - 36s - loss: 0.2128\n",
      "Epoch 11/15\n",
      "1854/1854 - 35s - loss: 0.2124\n",
      "Epoch 12/15\n",
      "1854/1854 - 35s - loss: 0.2126\n",
      "Epoch 13/15\n",
      "1854/1854 - 35s - loss: 0.2122\n",
      "Epoch 14/15\n",
      "1854/1854 - 35s - loss: 0.2121\n",
      "Epoch 15/15\n",
      "1854/1854 - 35s - loss: 0.2120\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fb648cc6040>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_samples_per_batch = 512\n",
    "\n",
    "model.fit_generator(\n",
    "    batchifier(pairs, positive_samples=positive_samples_per_batch, negative_ratio=10),\n",
    "    epochs=15,\n",
    "    steps_per_epoch=len(pairs) // positive_samples_per_batch,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Rogue One 1.0\n",
      "19 Interstellar (film) 0.9754495\n",
      "25 Star Wars sequel trilogy 0.9717135\n",
      "245 Gravity (film) 0.96680474\n",
      "659 Rise of the Planet of the Apes 0.9658743\n",
      "86 Tomorrowland (film) 0.9616978\n",
      "3349 Star Wars: The Force Awakens 0.9614974\n",
      "37 Avatar (2009 film) 0.9567715\n",
      "101 Prometheus (2012 film) 0.95547014\n",
      "1159 Cowboys & Aliens 0.953224\n"
     ]
    }
   ],
   "source": [
    "movie = model.get_layer('movie_embedding')\n",
    "movie_weights = movie.get_weights()[0]\n",
    "movie_lengths = np.linalg.norm(movie_weights, axis=1)\n",
    "normalized_movies = (movie_weights.T / movie_lengths).T\n",
    "\n",
    "def similar_movies(movie):\n",
    "    dists = np.dot(normalized_movies, normalized_movies[movie_to_idx[movie]])\n",
    "    closest = np.argsort(dists)[-10:]\n",
    "    for c in reversed(closest):\n",
    "        print(c, movies[c][0], dists[c])\n",
    "\n",
    "similar_movies('Rogue One')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 George Lucas 1.0\n",
      "2707 Star Wars 0.9517836\n",
      "3176 Star Wars (film) 0.948684\n",
      "4830 widescreen 0.9400084\n",
      "976 Hugo Award for Best Dramatic Presentation 0.93255466\n",
      "2829 storyboard 0.9103877\n",
      "2778 Lucasfilm 0.9086988\n",
      "4051 novelization 0.9070674\n",
      "2931 LaserDisc 0.9041462\n",
      "3040 Simon & Schuster 0.8941034\n"
     ]
    }
   ],
   "source": [
    "link = model.get_layer('link_embedding')\n",
    "link_weights = link.get_weights()[0]\n",
    "link_lengths = np.linalg.norm(link_weights, axis=1)\n",
    "normalized_links = (link_weights.T / link_lengths).T\n",
    "\n",
    "def similar_links(link):\n",
    "    dists = np.dot(normalized_links, normalized_links[link_to_idx[link]])\n",
    "    closest = np.argsort(dists)[-10:]\n",
    "    for c in reversed(closest):\n",
    "        print(c, top_links[c], dists[c])\n",
    "\n",
    "similar_links('George Lucas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(16, 50)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = ['Star Wars: The Force Awakens', 'The Martian (film)', 'Tangerine (film)', 'Straight Outta Compton (film)',\n",
    "        'Brooklyn (film)', 'Carol (film)', 'Spotlight (film)']\n",
    "worst = ['American Ultra', 'The Cobbler (2014 film)', 'Entourage (film)', 'Fantastic Four (2015 film)',\n",
    "         'Get Hard', 'Hot Pursuit (2015 film)', 'Mortdecai (film)', 'Serena (2014 film)', 'Vacation (2015 film)']\n",
    "y = np.asarray([1 for _ in best] + [0 for _ in worst])\n",
    "X = np.asarray([normalized_movies[movie_to_idx[movie]] for movie in best + worst])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(kernel='linear')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best:\n",
      "481 The Devil Wears Prada (film) 1.3620437031687356\n",
      "66 Skyfall 1.3350867532814488\n",
      "307 Les Mis√©rables (2012 film) 1.2106331746607621\n",
      "458 Hugo (film) 1.2058176549646533\n",
      "3 Spectre (2015 film) 1.136492770148211\n",
      "worst:\n",
      "1782 Scooby-Doo! WrestleMania Mystery -1.5782615809457672\n",
      "1878 The Little Rascals (film) -1.571271394484349\n",
      "8559 Air Buddies -1.5426240639665845\n",
      "9595 Speed Zone -1.535464468172866\n",
      "5097 Ready to Rumble -1.5338072240563094\n"
     ]
    }
   ],
   "source": [
    "estimated_movie_ratings = clf.decision_function(normalized_movies)\n",
    "best = np.argsort(estimated_movie_ratings)\n",
    "print('best:')\n",
    "for c in reversed(best[-5:]):\n",
    "    print(c, movies[c][0], estimated_movie_ratings[c])\n",
    "\n",
    "print('worst:')\n",
    "for c in best[:5]:\n",
    "    print(c, movies[c][0], estimated_movie_ratings[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_y = np.asarray([float(movie[-2][:-1]) / 100 for movie in movies if movie[-2]])\n",
    "rotten_X = np.asarray([normalized_movies[movie_to_idx[movie[0]]] for movie in movies if movie[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_CUT_OFF = int(len(rotten_X) * 0.8)\n",
    "regr = LinearRegression()\n",
    "regr.fit(rotten_X[:TRAINING_CUT_OFF], rotten_y[:TRAINING_CUT_OFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'mean square error 0.06'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (regr.predict(rotten_X[TRAINING_CUT_OFF:]) - rotten_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'mean square error 0.09'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (np.mean(rotten_y[:TRAINING_CUT_OFF]) - rotten_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 The Martian (film) 10900.0\n",
      "7 List of Marvel Cinematic Universe films 4300.0\n",
      "49 Back to the Future 3900.0\n",
      "71 The Conjuring 2932.0\n",
      "162 Thor (film) 2464.0\n",
      "36 Furious 7 2340.0\n",
      "30 Finding Dory 2187.0\n",
      "1906 Jane Eyre (2011 film) 2068.0\n",
      "19 Interstellar (film) 1670.0\n",
      "2251 An American Werewolf in London 1655.0\n"
     ]
    }
   ],
   "source": [
    "def gross(movie):\n",
    "    v = movie[1].get('gross')\n",
    "    if not v or not ' ' in v:\n",
    "        return None\n",
    "    v, unit = v.split(' ', 1)\n",
    "    unit = unit.lower()\n",
    "    if not unit in ('million', 'billion'):\n",
    "        return None\n",
    "    if not v.startswith('$'):\n",
    "        return None\n",
    "    try:\n",
    "        v = float(v[1:])\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if unit == 'billion':\n",
    "        v *= 1000\n",
    "    return v\n",
    "\n",
    "movie_gross = [gross(m) for m in movies]\n",
    "movie_gross = np.asarray([gr for gr in movie_gross if gr is not None])\n",
    "highest = np.argsort(movie_gross)[-10:]\n",
    "for c in reversed(highest):\n",
    "    print(c, movies[c][0], movie_gross[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_y = np.asarray([gr for gr in movie_gross if gr])\n",
    "gross_X = np.asarray([normalized_movies[movie_to_idx[movie[0]]] for movie, gr in zip(movies, movie_gross) if gr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_CUT_OFF = int(len(gross_X) * 0.8)\n",
    "regr = LinearRegression()\n",
    "regr.fit(gross_X[:TRAINING_CUT_OFF], gross_y[:TRAINING_CUT_OFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'mean square error 8831.23'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (regr.predict(gross_X[TRAINING_CUT_OFF:]) - gross_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'mean square error 14115.59'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (np.mean(gross_y[:TRAINING_CUT_OFF]) - gross_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}