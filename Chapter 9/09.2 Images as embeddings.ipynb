{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "from IPython.display import HTML, Image, display\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "import os\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from functools import partial\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn import svm\n",
    "import numpy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace with your own. These belong to a dissabled app:\n",
    "FLICKR_KEY = 'c9511f1328036f0ae49f0538dedff432'\n",
    "FLICKR_SECRET = '892eb48de6cc87e1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flickr = flickrapi.FlickrAPI(FLICKR_KEY, FLICKR_SECRET, format='parsed-json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flickr_url(photo, size=''):\n",
    "    url = 'http://farm{farm}.staticflickr.com/{server}/{id}_{secret}{size}.jpg'\n",
    "    if size:\n",
    "        size = '_' + size\n",
    "    return url.format(size=size, **photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = flickr.photos.search(text='\"cat\"', per_page='10', sort='relevance')\n",
    "photos = res['photos']['photo']\n",
    "tags = ['<img src=\"{}\" width=\"150\" style=\"display:inline\"/>'.format(flickr_url(photo)) for photo in photos]\n",
    "HTML(''.join(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_photo(dir_name, photo):\n",
    "    urlretrieve(flickr_url(photo), os.path.join(dir_name, photo['id'] + '.jpg'))\n",
    "\n",
    "def fetch_image_set(query, dir_name=None, count=250, sort='relevance'):\n",
    "    res = flickr.photos.search(text='\"{}\"'.format(query), \n",
    "                               per_page=count, sort=sort)['photos']['photo']\n",
    "    dir_name = dir_name or query\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    with multiprocessing.Pool() as p:\n",
    "        p.map(partial(fetch_photo, dir_name), res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_image_set('cat')\n",
    "fetch_image_set('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = [image.load_img(p, target_size=(224, 224)) \n",
    "          for p in glob('cat/*jpg') + glob('dog/*jpg')]\n",
    "tensor = np.asarray([image.img_to_array(img) for img in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(p, [1] * 250 + [0] * 250, test_size=0.20, random_state=42)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train) \n",
    "sum(1 for p, t in zip(clf.predict(X_test), y_test) if p != t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = {tuple(a): b for a, b in zip(p, glob('cat/*jpg') + glob('dog/*jpg'))}\n",
    "wrong = [mm[tuple(a)] for a, p, t in zip(X_test, clf.predict(X_test), y_test) if p != t]\n",
    "\n",
    "for x in wrong:\n",
    "    display(Image(x, width=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_image_set('cat', dir_name='maybe_cat', count=100, sort='recent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maybe_cat_fns = glob('maybe_cat/*jpg')\n",
    "maybe_cats = [image.load_img(p, target_size=(224, 224)) \n",
    "              for p in maybe_cat_fns]\n",
    "maybe_cat_tensor = np.asarray([image.img_to_array(img) \n",
    "                              for img in maybe_cats])\n",
    "maybe_cat_vectors = model.predict(maybe_cat_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = maybe_cat_vectors.sum(axis=0) / len(maybe_cats)\n",
    "centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = maybe_cat_vectors - centroid\n",
    "distances = numpy.linalg.norm(diffs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idxs = np.argsort(distances)\n",
    "for worst_cat_idx in sorted_idxs[-10:]:\n",
    "    display(Image(maybe_cat_fns[worst_cat_idx], width=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = 90\n",
    "sorted_idxs_i = sorted_idxs\n",
    "for i in range(5):\n",
    "    centroid_i = maybe_cat_vectors[sorted_idxs_i[:-to_drop]].sum(axis=0) / (len(maybe_cat_fns) - to_drop)\n",
    "    distances_i = numpy.linalg.norm(maybe_cat_vectors - centroid_i, axis=1)\n",
    "    sorted_idxs_i = np.argsort(distances_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for worst_cat_idx in sorted_idxs_i[:5]:\n",
    "    display(Image(maybe_cat_fns[worst_cat_idx], width=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}