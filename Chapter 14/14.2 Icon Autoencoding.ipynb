{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Reshape, Concatenate, Flatten, Lambda\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy, kullback_leibler_divergence\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import PIL\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_icons(train_size=0.85):\n",
    "    icon_index = json.load(open('icons/index.json'))\n",
    "    x = []\n",
    "    img_rows, img_cols = 32, 32\n",
    "    for icon in icon_index:\n",
    "        if icon['name'].endswith('_filled'):\n",
    "            continue\n",
    "        img_path = 'icons/png32/%s.png' % icon['name']\n",
    "        img = load_img(img_path, grayscale=True, target_size=(img_rows, img_cols))\n",
    "        img = img_to_array(img)\n",
    "        x.append(img)\n",
    "    x = np.asarray(x) / 255\n",
    "    x_train, x_val = train_test_split(x, train_size=train_size)\n",
    "    return x_train, x_val\n",
    "\n",
    "x_train, x_test = load_icons()\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder():\n",
    "    input_img = Input(shape=(32, 32, 1))\n",
    "\n",
    "    channels = 4\n",
    "    x = input_img\n",
    "    for i in range(5):\n",
    "        left = Conv2D(channels, (3, 3), activation='relu', padding='same')(x)\n",
    "        right = Conv2D(channels, (2, 2), activation='relu', padding='same')(x)\n",
    "        conc = Concatenate()([left, right])\n",
    "        x = MaxPooling2D((2, 2), padding='same')(conc)\n",
    "        channels *= 2\n",
    "\n",
    "    x = Dense(channels)(x)\n",
    "\n",
    "    for i in range(5):\n",
    "        x = Conv2D(channels, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        channels //= 2\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder = create_autoencoder()\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 25\n",
    "idx = np.random.randint(x_test.shape[0], size=cols)\n",
    "sample = x_test[idx]\n",
    "decoded_imgs = autoencoder.predict(sample)\n",
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(tile):\n",
    "    tile = tile.reshape(tile.shape[:-1])\n",
    "    tile = np.clip(tile * 255, 0, 255)\n",
    "    return PIL.Image.fromarray(tile)\n",
    "    \n",
    "\n",
    "overview = PIL.Image.new('RGB', (cols * 36 + 4, 64 + 12), (128, 128, 128))\n",
    "for idx in range(cols):\n",
    "    overview.paste(decode_img(sample[idx]), (idx * 36 + 4, 4))\n",
    "    overview.paste(decode_img(decoded_imgs[idx]), (idx * 36 + 4, 40))\n",
    "f = BytesIO()\n",
    "overview.save(f, 'png')\n",
    "display(Image(data=f.getvalue()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(icons):\n",
    "    aug_icons = []\n",
    "    for icon in icons:\n",
    "        for flip in range(4):\n",
    "            for rotation in range(4):\n",
    "                aug_icons.append(icon)\n",
    "                icon = np.rot90(icon)\n",
    "            icon = np.fliplr(icon)\n",
    "    return np.asarray(aug_icons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_aug = augment(x_train)\n",
    "x_test_aug = augment(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "autoencoder = create_autoencoder()\n",
    "autoencoder.fit(x_train_aug, x_train_aug,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_aug, x_test_aug),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 25\n",
    "idx = np.random.randint(x_test.shape[0], size=cols)\n",
    "sample = x_test[idx]\n",
    "decoded_imgs = autoencoder.predict(sample)\n",
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(tile, factor=1.0):\n",
    "    tile = tile.reshape(tile.shape[:-1])\n",
    "    tile = np.clip(tile * 255, 0, 255)\n",
    "    return PIL.Image.fromarray(tile)\n",
    "    \n",
    "\n",
    "overview = PIL.Image.new('RGB', (cols * 32, 64 + 20), (128, 128, 128))\n",
    "for idx in range(cols):\n",
    "    overview.paste(decode_img(sample[idx]), (idx * 32, 5))\n",
    "    overview.paste(decode_img(decoded_imgs[idx]), (idx * 32, 42))\n",
    "f = BytesIO()\n",
    "overview.save(f, 'png')\n",
    "display(Image(data=f.getvalue()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "latent_space_depth = 128\n",
    "\n",
    "def sample_z(args):\n",
    "    z_mean, z_log_var = args\n",
    "    eps = K.random_normal(shape=(batch_size, latent_space_depth), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VariationalAutoEncoder(num_pixels):\n",
    "    \n",
    "    input_img = Input(shape=(32, 32, 1))\n",
    "\n",
    "    channels = 4\n",
    "    x = input_img\n",
    "    for i in range(5):\n",
    "        left = Conv2D(channels, (3, 3), activation='relu', padding='same')(x)\n",
    "        right = Conv2D(channels, (2, 2), activation='relu', padding='same')(x)\n",
    "        conc = Concatenate()([left, right])\n",
    "        x = MaxPooling2D((2, 2), padding='same')(conc)\n",
    "        channels *= 2\n",
    "\n",
    "    x = Dense(channels)(x)\n",
    "    encoder_hidden = Flatten()(x)\n",
    "\n",
    "    z_mean = Dense(latent_space_depth, activation='linear')(encoder_hidden)\n",
    "    z_log_var = Dense(latent_space_depth, activation='linear')(encoder_hidden)\n",
    "    \n",
    "    def KL_loss(y_true, y_pred):\n",
    "        return 0.0001 * K.sum(K.exp(z_log_var) + K.square(z_mean) - 1 - z_log_var, axis=1)\n",
    "\n",
    "    def reconstruction_loss(y_true, y_pred):\n",
    "        y_true = K.batch_flatten(y_true)\n",
    "        y_pred = K.batch_flatten(y_pred)\n",
    "        return binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def total_loss(y_true, y_pred):\n",
    "        return reconstruction_loss(y_true, y_pred) + KL_loss(y_true, y_pred)\n",
    "\n",
    "    z = Lambda(sample_z, output_shape=(latent_space_depth, ))([z_mean, z_log_var])\n",
    "    decoder_in = Input(shape=(latent_space_depth,))\n",
    "\n",
    "    d_x = Reshape((1, 1, latent_space_depth))(decoder_in)\n",
    "    e_x = Reshape((1, 1, latent_space_depth))(z)\n",
    "    for i in range(5):\n",
    "        conv = Conv2D(channels, (3, 3), activation='relu', padding='same')\n",
    "        upsampling = UpSampling2D((2, 2))\n",
    "        d_x = conv(d_x)\n",
    "        d_x = upsampling(d_x)\n",
    "        e_x = conv(e_x)\n",
    "        e_x = upsampling(e_x)\n",
    "        channels //= 2\n",
    "\n",
    "    final_conv = Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    auto_decoded = final_conv(e_x)\n",
    "    decoder_out = final_conv(d_x)\n",
    "    \n",
    "    decoder = Model(decoder_in, decoder_out)    \n",
    "    \n",
    "    auto_encoder = Model(input_img, auto_decoded)\n",
    "\n",
    "    auto_encoder.compile(optimizer=Adam(lr=0.001), \n",
    "                         loss=total_loss,\n",
    "                         metrics=[KL_loss, reconstruction_loss])\n",
    "    \n",
    "    return auto_encoder, decoder\n",
    "\n",
    "var_auto_encoder, decoder = VariationalAutoEncoder(32)\n",
    "var_auto_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_to_batch(x):\n",
    "    l = x.shape[0]\n",
    "    return x[:l - l % batch_size, :, :, :]\n",
    "\n",
    "x_train_trunc = truncate_to_batch(x_train)\n",
    "x_test_trunc = truncate_to_batch(x_test)\n",
    "x_train_trunc.shape, x_test_trunc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_auto_encoder.fit(x_train_trunc, x_train_trunc, verbose=1, \n",
    "                 batch_size=batch_size, epochs=100,\n",
    "                 validation_data=(x_test_trunc, x_test_trunc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_number = np.asarray([[np.random.normal() \n",
    "                            for _ in range(latent_space_depth)]])\n",
    "img_width, img_height = 32, 32\n",
    "def decode_img(a):\n",
    "    a = np.clip(a * 256, 0, 255).astype('uint8')\n",
    "    return PIL.Image.fromarray(a)\n",
    "\n",
    "decode_img(decoder.predict(random_number).reshape(img_width, img_height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells = 10\n",
    "\n",
    "overview = PIL.Image.new('RGB', \n",
    "                         (num_cells * (img_width + 4) + 8, \n",
    "                          num_cells * (img_height + 4) + 8), \n",
    "                         (140, 128, 128))\n",
    "for x in range(num_cells):\n",
    "    for y in range(num_cells):\n",
    "        vec = np.asarray([[np.random.normal() * 1.4 \n",
    "                            for _ in range(latent_space_depth)]])\n",
    "        decoded = decoder.predict(vec)\n",
    "        img = decode_img(decoded.reshape(img_width, img_height))\n",
    "        overview.paste(img, (x * (img_width + 4) + 6, y * (img_height + 4) + 6))\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_to_batch(x):\n",
    "    l = x.shape[0]\n",
    "    return x[:l - l % batch_size, :, :, :]\n",
    "\n",
    "x_train_trunc = truncate_to_batch(x_train_aug)\n",
    "x_test_trunc = truncate_to_batch(x_test_aug)\n",
    "x_train_trunc.shape, x_test_trunc.shape\n",
    "\n",
    "var_auto_encoder.fit(x_train_trunc, x_train_trunc, verbose=1, \n",
    "                 batch_size=batch_size, epochs=100,\n",
    "                 validation_data=(x_test_trunc, x_test_trunc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells = 10\n",
    "\n",
    "overview = PIL.Image.new('RGB', \n",
    "                         (num_cells * (img_width + 4) + 8, \n",
    "                          num_cells * (img_height + 4) + 8), \n",
    "                         (140, 128, 128))\n",
    "for x in range(num_cells):\n",
    "    for y in range(num_cells):\n",
    "        vec = np.asarray([[np.random.normal() * 1.2 \n",
    "                            for _ in range(latent_space_depth)]])\n",
    "        decoded = decoder.predict(vec)\n",
    "        img = decode_img(decoded.reshape(img_width, img_height))\n",
    "        overview.paste(img, (x * (img_width + 4) + 6, y * (img_height + 4) + 6))\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells = 10\n",
    "\n",
    "overview = PIL.Image.new('RGB', \n",
    "                         (num_cells * (img_width + 4) + 8, \n",
    "                          num_cells * (img_height + 4) + 8), \n",
    "                         (140, 128, 128))\n",
    "for x in range(num_cells):\n",
    "    for y in range(num_cells):\n",
    "        vec = np.asarray([[ - (i % 2) * (x - 4.5) / 3 + ((i + 1) % 2) * (y - 4.5) / 3\n",
    "                            for i in range(latent_space_depth)]])\n",
    "        decoded = decoder.predict(vec)\n",
    "        img = decode_img(decoded.reshape(img_width, img_height))\n",
    "        overview.paste(img, (x * (img_width + 4) + 6, y * (img_height + 4) + 6))\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.asarray([[np.random.normal() \n",
    "                    for _ in range(latent_space_depth)]])\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray([[np.random.normal() \n",
    "                    for _ in range(latent_space_depth)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}