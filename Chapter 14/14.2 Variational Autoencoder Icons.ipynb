{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Reshape, Concatenate\n",
    "from keras.layers.merge import concatenate as concat\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "from collections import Counter\n",
    "from io import BytesIO\n",
    "import PIL\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250 # batch size\n",
    "\n",
    "def augment(icons, labels, size):\n",
    "    aug_icons = []\n",
    "    aug_labels = []\n",
    "    for icon, label in zip(icons, labels):\n",
    "        for flip in range(4):\n",
    "            for rotation in range(4):\n",
    "                aug_icons.append(icon)\n",
    "                aug_labels.append(label)\n",
    "                icon = np.rot90(icon)\n",
    "            icon = np.fliplr(icon)\n",
    "            if flip % 2 == 0:\n",
    "                icon = np.flipud(icon)\n",
    "    aug_icons = np.asarray(aug_icons) / 255\n",
    "\n",
    "    return aug_icons, np.asarray(aug_labels)\n",
    "\n",
    "def load_icons(train_size=0.90, size=28):\n",
    "    icon_index = json.load(open('icons/index.json'))\n",
    "    cat_count = Counter(icon['category'] for icon in icon_index)\n",
    "    cats = [cat for cat, count in cat_count.items() if count > 50]\n",
    "    cat_to_index = {cat: idx for idx, cat in enumerate(cats)}\n",
    "    x = []\n",
    "    y = []\n",
    "    img_rows, img_cols = size, size\n",
    "    for icon in icon_index:\n",
    "        if icon['name'].endswith('_filled'):\n",
    "            continue\n",
    "        cat_idx = cat_to_index.get(icon['category'])\n",
    "        if cat_idx is None:\n",
    "            continue\n",
    "        img_path = 'icons/png%d/%s.png' % (size, icon['name'])\n",
    "        img = load_img(img_path, grayscale=True, target_size=(img_rows, img_cols))\n",
    "        img = img_to_array(img)\n",
    "        x.append(img)\n",
    "        y.append(cat_idx)\n",
    "    target_size = len(x) - (len(x) % batch_size)\n",
    "    x = x[:target_size]\n",
    "    y = y[:target_size]\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    train_size = int(train_size * x.shape[0])\n",
    "    train_size -= train_size % batch_size\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_size)\n",
    "    x_train, y_train = augment(x_train, y_train, size=size)\n",
    "    x_test, y_test = augment(x_test, y_test, size=size)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = load_icons(size=32)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "latent_space_depth = 128\n",
    "\n",
    "def sample_z(args):\n",
    "    z_mean, z_log_var = args\n",
    "    eps = K.random_normal(shape=(batch_size, latent_space_depth), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var / 2) * eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VariationalAutoEncoder(num_pixels):\n",
    "    pixels = Input(shape=(num_pixels, num_pixels, 1))\n",
    "    channels = 4\n",
    "    x = pixels\n",
    "    for i in range(4):\n",
    "        left = Conv2D(channels, (3, 3), activation='relu', padding='same')(x)\n",
    "        right = Conv2D(channels, (2, 2), activation='relu', padding='same')(x)\n",
    "        conc = Concatenate()([left, right])\n",
    "        x = MaxPooling2D((2, 2), padding='same')(conc)\n",
    "        channels *= 2\n",
    "\n",
    "    x = Dense(32)(x) \n",
    "    x = Flatten()(x)\n",
    "    encoder_hidden = Dense(latent_space_depth, name='encoder_hidden')(x)\n",
    "\n",
    "    z_mean = Dense(latent_space_depth, activation='linear', name='z_mean')(encoder_hidden)\n",
    "    z_log_var = Dense(latent_space_depth, activation='linear', name='z_log_var')(encoder_hidden)\n",
    "    \n",
    "    def KL_loss(y_true, y_pred):\n",
    "        return 0.5 * K.sum(K.exp(z_log_var) + K.square(z_mean) - 1 - z_log_var, axis=1)\n",
    "\n",
    "    def reconstruction_loss(y_true, y_pred):\n",
    "        y_true = K.batch_flatten(y_true)\n",
    "        y_pred = K.batch_flatten(y_pred)\n",
    "        return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)    \n",
    "\n",
    "    def total_loss(y_true, y_pred):\n",
    "        return KL_loss(y_true, y_pred) + reconstruction_loss(y_true, y_pred)\n",
    "\n",
    "    z = Lambda(sample_z, output_shape=(latent_space_depth, ))([z_mean, z_log_var])\n",
    "    \n",
    "    up_samp0 = UpSampling2D((2, 2))\n",
    "    up_conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')\n",
    "    up_samp1 = UpSampling2D((2, 2))\n",
    "    up_conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')\n",
    "    up_samp2 = UpSampling2D((2, 2))\n",
    "    up_conv3 = Conv2D(8, (3, 3), activation='relu', padding='same')\n",
    "    up_samp3 = UpSampling2D((2, 2))\n",
    "    up_conv4 = Conv2D(4, (3, 3), activation='relu', padding='same')\n",
    "    up_samp4 = UpSampling2D((2, 2))\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "\n",
    "    decoder_in = Input(shape=(latent_space_depth,))\n",
    "    d_x = Reshape((1, 1, latent_space_depth))(decoder_in)\n",
    "    d_x = up_samp0(d_x)\n",
    "    d_x = up_conv1(d_x)\n",
    "    d_x = up_samp1(d_x)\n",
    "    d_x = up_conv2(d_x)\n",
    "    d_x = up_samp2(d_x)\n",
    "    d_x = up_conv3(d_x)\n",
    "    d_x = up_samp3(d_x)\n",
    "    d_x = up_conv4(d_x)\n",
    "    d_x = up_samp4(d_x)\n",
    "    decoder_out= decoded(d_x)\n",
    "\n",
    "    decoder = Model(decoder_in, decoder_out)    \n",
    "\n",
    "    a_x = Reshape((1, 1, latent_space_depth))(z)\n",
    "    a_x = up_samp0(a_x)\n",
    "    a_x = up_conv1(a_x)\n",
    "    a_x = up_samp1(a_x)\n",
    "    a_x = up_conv2(a_x)\n",
    "    a_x = up_samp2(a_x)\n",
    "    a_x = up_conv3(a_x)\n",
    "    a_x = up_samp3(a_x)\n",
    "    a_x = up_conv4(a_x)\n",
    "    a_x = up_samp4(a_x)\n",
    "    outputs= decoded(a_x)\n",
    "    \n",
    "    auto_encoder = Model(pixels, outputs)\n",
    "\n",
    "    auto_encoder.compile(optimizer=Adam(lr=0.001), \n",
    "                         loss=total_loss,\n",
    "                         metrics=[KL_loss, reconstruction_loss])\n",
    "    \n",
    "    return auto_encoder, decoder\n",
    "\n",
    "auto_encoder, decoder = VariationalAutoEncoder(x_train.shape[1])\n",
    "auto_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto_encoder.fit(x_train, x_train, verbose=1, \n",
    "                 batch_size=batch_size, epochs=100,\n",
    "                 validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_number = np.asarray([[np.random.normal() \n",
    "                            for _ in range(latent_space_depth)]])\n",
    "print(random_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 32, 32\n",
    "def decode_img(a):\n",
    "    a = np.clip(a * 256, 0, 255).astype('uint8')\n",
    "    return PIL.Image.fromarray(a)\n",
    "\n",
    "decode_img(decoder.predict(random_number).reshape(img_width, img_height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_cells = 10\n",
    "\n",
    "overview = PIL.Image.new('RGB', \n",
    "                         (num_cells * (img_width + 4) + 8, \n",
    "                          num_cells * (img_height + 4) + 8), \n",
    "                         (140, 128, 128))\n",
    "\n",
    "for x in range(num_cells):\n",
    "    for y in range(num_cells):\n",
    "        vec = np.asarray([[np.random.normal() \n",
    "                            for _ in range(latent_space_depth)]])\n",
    "        decoded = decoder.predict(vec)\n",
    "        img = decode_img(decoded.reshape(img_width, img_height))\n",
    "        overview.paste(img, (x * (img_width + 4) + 6, y * (img_height + 4) + 6))\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells = 10\n",
    "\n",
    "overview = PIL.Image.new('RGB', \n",
    "                         (num_cells * (img_width + 4) + 8, \n",
    "                          num_cells * (img_height + 4) + 8), \n",
    "                         (128, 128, 128))\n",
    "\n",
    "vec = np.zeros((1, latent_space_depth))\n",
    "for x in range(num_cells):\n",
    "    vec[: 1] = (x * 3) / (num_cells - 1) - 1.5\n",
    "    for y in range(num_cells):\n",
    "#        vec[: 1] = (y * 3) / (num_cells - 1) - 1.5\n",
    "        decoded = decoder.predict(vec)\n",
    "        img = decode_img(decoded.reshape(img_width, img_height))\n",
    "        overview.paste(img, (x * (img_width + 4) + 6, y * (img_height + 4) + 6))\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "263px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}