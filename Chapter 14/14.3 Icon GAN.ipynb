{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Conv2DTranspose, BatchNormalization, LeakyReLU\n",
    "from keras.layers import Activation, Conv2D, Lambda, Concatenate, Flatten, Dense, UpSampling2D\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "import colorsys\n",
    "import keras.backend as K\n",
    "import glob\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import BytesIO\n",
    "import PIL\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LATENT_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(icons):\n",
    "    aug_icons = []\n",
    "    for icon in icons:\n",
    "        for flip in range(4):\n",
    "            for rotation in range(4):\n",
    "                aug_icons.append(icon)\n",
    "                icon = np.rot90(icon)\n",
    "            icon = np.fliplr(icon)\n",
    "    return np.asarray(aug_icons)\n",
    "        \n",
    "\n",
    "def load_icons(train_size=0.85):\n",
    "    icon_index = json.load(open('icons/index.json'))\n",
    "    x = []\n",
    "    img_rows, img_cols = 32, 32\n",
    "    for icon in icon_index:\n",
    "        if icon['name'].endswith('_filled'):\n",
    "            continue\n",
    "        img_path = 'icons/png32/%s.png' % icon['name']\n",
    "        img = load_img(img_path, grayscale=True, target_size=(img_rows, img_cols))\n",
    "        img = img_to_array(img)\n",
    "        x.append(img)\n",
    "    x = np.asarray(x) / 255\n",
    "    x_train, x_val = train_test_split(x, train_size=train_size)\n",
    "    return augment(x_train), augment(x_val)\n",
    "\n",
    "x_train, x_test = load_icons()\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generative_network(latent_size):\n",
    "    inp = Input(shape=(latent_size,))\n",
    "    x = Reshape((1, 1, latent_size))(inp)\n",
    "\n",
    "    channels = latent_size\n",
    "    padding = 'valid'\n",
    "    strides = 1\n",
    "    for i in range(4):\n",
    "        x = Conv2DTranspose(channels, kernel_size=4,\n",
    "                            strides=strides, padding=padding)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(.2)(x)\n",
    "        \n",
    "        channels //= 2\n",
    "        padding = 'same'\n",
    "        strides = 2\n",
    "\n",
    "    x = Conv2DTranspose(1, kernel_size=4, strides=1, padding='same')(x)\n",
    "    image_out = Activation('tanh')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=image_out)\n",
    "    return model\n",
    "\n",
    "generator = create_generative_network(LATENT_SIZE)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminative_network():\n",
    "    inp = Input(shape=(32, 32, 1))\n",
    "    x = inp\n",
    "\n",
    "    channels = 16\n",
    "\n",
    "    for i in range(4):\n",
    "        layers = []\n",
    "        conv = Conv2D(channels, 3, strides=2, padding='same')(x)\n",
    "        if i:\n",
    "            conv = BatchNormalization()(conv)\n",
    "        conv = LeakyReLU(.2)(conv)\n",
    "        layers.append(conv)\n",
    "        bv = Lambda(lambda x: K.mean(K.abs(x[:] - K.mean(x, axis=0)), \n",
    "                                     axis=-1, \n",
    "                                     keepdims=True))(conv)\n",
    "        layers.append(bv)\n",
    "        channels *= 2\n",
    "        x = Concatenate()(layers)\n",
    "\n",
    "    x = Conv2D(128, 2, padding='valid')(x)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    fake = Dense(1, activation='sigmoid', name='generation')(x)\n",
    "\n",
    "    m = Model(inputs=inp, outputs=fake)\n",
    "    return m\n",
    "\n",
    "discriminator = create_discriminative_network()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(g, d):\n",
    "    # initialize a GAN trainer\n",
    "\n",
    "    # this is the fastest way to train a GAN in Keras\n",
    "    # two models are updated simutaneously in one pass\n",
    "\n",
    "    noise = Input(shape=g.input_shape[1:])\n",
    "    real_data = Input(shape=d.input_shape[1:])\n",
    "\n",
    "    generated = g(noise)\n",
    "    gscore = d(generated)\n",
    "    rscore = d(real_data)\n",
    "\n",
    "    def log_eps(i):\n",
    "        return K.log(i+1e-11)\n",
    "\n",
    "    # single side label smoothing: replace 1.0 with 0.9\n",
    "    dloss = - K.mean(log_eps(1-gscore) + .1 * log_eps(1-rscore) + .9 * log_eps(rscore))\n",
    "    gloss = - K.mean(log_eps(gscore))\n",
    "\n",
    "    Adam = tf.train.AdamOptimizer\n",
    "\n",
    "    lr, b1 = 1e-4, .2 # otherwise won't converge.\n",
    "    optimizer = Adam(lr,beta1=b1)\n",
    "\n",
    "    grad_loss_wd = optimizer.compute_gradients(dloss, d.trainable_weights)\n",
    "    update_wd = optimizer.apply_gradients(grad_loss_wd)\n",
    "\n",
    "    grad_loss_wg = optimizer.compute_gradients(gloss, g.trainable_weights)\n",
    "    update_wg = optimizer.apply_gradients(grad_loss_wg)\n",
    "\n",
    "    def get_internal_updates(model):\n",
    "        # get all internal update ops (like moving averages) of a model\n",
    "        inbound_nodes = model.inbound_nodes\n",
    "        input_tensors = []\n",
    "        for ibn in inbound_nodes:\n",
    "            input_tensors+= ibn.input_tensors\n",
    "        updates = [model.get_updates_for(i) for i in input_tensors]\n",
    "        return updates\n",
    "\n",
    "    other_parameter_updates = [get_internal_updates(m) for m in [d,g]]\n",
    "    # those updates includes batch norm.\n",
    "\n",
    "    train_step = [update_wd, update_wg, other_parameter_updates]\n",
    "    losses = [dloss, gloss]\n",
    "\n",
    "    learning_phase = K.learning_phase()\n",
    "\n",
    "    def gan_feed(sess,batch_image,z_input):\n",
    "        # actual GAN trainer\n",
    "        nonlocal train_step,losses,noise,real_data,learning_phase\n",
    "\n",
    "        res = sess.run([train_step,losses],feed_dict={\n",
    "        noise:z_input,\n",
    "        real_data:batch_image,\n",
    "        learning_phase:True,\n",
    "        # Keras layers needs to know whether\n",
    "        # this run is training or testring (you know, batch norm and dropout)\n",
    "        })\n",
    "\n",
    "        loss_values = res[1]\n",
    "        return loss_values #[dloss,gloss]\n",
    "\n",
    "    return gan_feed\n",
    "\n",
    "print('generating GAN...')\n",
    "gan_feed = gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator, count):\n",
    "    noise = np.random.normal(loc=0., \n",
    "                             scale=1., \n",
    "                             size=(count, LATENT_SIZE))\n",
    "    for tile in generator.predict([noise]).reshape((count, 32, 32)):\n",
    "        tile = (tile * 300).clip(0, 255).astype('uint8')\n",
    "        yield PIL.Image.fromarray(tile)\n",
    "\n",
    "def poster(generator, w_count, h_count):\n",
    "    overview = PIL.Image.new('RGB', (w_count * 34 + 2, h_count * 34 + 2), (128, 128, 128))\n",
    "    for idx, img in enumerate(generate_images(generator, w_count * h_count)):\n",
    "        x = idx % w_count\n",
    "        y = idx // w_count\n",
    "        overview.paste(img, (x * 34 + 2, y * 34 + 2))\n",
    "    return overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(epochs=100):\n",
    "    sess = K.get_session()\n",
    "    l = x_train.shape[0]\n",
    "    l -= l % BATCH_SIZE\n",
    "    for epoch in range(epochs):\n",
    "        np.random.shuffle(x_train)\n",
    "        for batch_start in range(0, l, BATCH_SIZE):\n",
    "            batch = x_train[batch_start: batch_start + BATCH_SIZE]\n",
    "            z_input = np.random.normal(loc=0., \n",
    "                                       scale=1., \n",
    "                                       size=(BATCH_SIZE, LATENT_SIZE))\n",
    "            dloss, gloss = gan_feed(sess, batch, z_input)\n",
    "        clear_output(wait=True)\n",
    "        print('%d dloss: %2.2f gloss: %2.2f' % (epoch, dloss, gloss))\n",
    "        f = BytesIO()\n",
    "        poster(generator, 8, 5).save(f, 'png')\n",
    "        display(Image(data=f.getvalue()))\n",
    "run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = BytesIO()\n",
    "poster(generator, 24, 12).save(f, 'png')\n",
    "display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}