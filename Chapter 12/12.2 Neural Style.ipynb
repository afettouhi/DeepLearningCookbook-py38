{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications import vgg16, vgg19\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import imageio\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from itertools import combinations\n",
    "\n",
    "# from scipy.misc import imread, imresize, imsave, fromimage, toimage\n",
    "\n",
    "try:\n",
    "    from io import BytesIO\n",
    "except ImportError:\n",
    "    from StringIO import StringIO as BytesIO\n",
    "import PIL\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_image_path = '../data/style_transfer/Okerk2.jpg'\n",
    "style1_image_path = '../data/style_transfer/water-lilies-1919-2.jpg'\n",
    "style2_image_path = '../data/style_transfer/VanGogh-starry_night_ballance1.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "\n",
    "def preprocess_image(image_path, target_size=None):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg16.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x, w, h):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, w, h))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((w, h, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-7a0c22075083>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m740\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m468\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mstyle_image\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvariable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreprocess_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstyle1_image_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mresult_image\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplaceholder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstyle_image\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m input_tensor = K.concatenate([style_image,\n\u001B[1;32m      5\u001B[0m                               result_image], axis=0)\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001B[0m in \u001B[0;36mvariable\u001B[0;34m(value, dtype, name, constraint)\u001B[0m\n\u001B[1;32m    839\u001B[0m     \u001B[0mv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_keras_shape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msparse_coo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    840\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 841\u001B[0;31m   v = variables_module.Variable(\n\u001B[0m\u001B[1;32m    842\u001B[0m       \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    843\u001B[0m       \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtypes_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    259\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variable_v1_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    260\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mcls\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mVariable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 261\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variable_v2_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    262\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    263\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mVariableMetaclass\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001B[0m in \u001B[0;36m_variable_v2_call\u001B[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001B[0m\n\u001B[1;32m    241\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0maggregation\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    242\u001B[0m       \u001B[0maggregation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVariableAggregation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNONE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 243\u001B[0;31m     return previous_getter(\n\u001B[0m\u001B[1;32m    244\u001B[0m         \u001B[0minitial_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitial_value\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    245\u001B[0m         \u001B[0mtrainable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrainable\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(**kws)\u001B[0m\n\u001B[1;32m    234\u001B[0m                         shape=None):\n\u001B[1;32m    235\u001B[0m     \u001B[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 236\u001B[0;31m     \u001B[0mprevious_getter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkws\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mdefault_variable_creator_v2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkws\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    237\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgetter\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variable_creator_stack\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    238\u001B[0m       \u001B[0mprevious_getter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_make_getter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgetter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprevious_getter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\u001B[0m in \u001B[0;36mdefault_variable_creator_v2\u001B[0;34m(next_creator, **kwargs)\u001B[0m\n\u001B[1;32m   2632\u001B[0m   \u001B[0mshape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"shape\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2633\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2634\u001B[0;31m   return resource_variable_ops.ResourceVariable(\n\u001B[0m\u001B[1;32m   2635\u001B[0m       \u001B[0minitial_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitial_value\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2636\u001B[0m       \u001B[0mtrainable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrainable\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    261\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variable_v2_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    262\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 263\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mVariableMetaclass\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001B[0m\n\u001B[1;32m   1421\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_from_proto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvariable_def\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimport_scope\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mimport_scope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1422\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1423\u001B[0;31m       self._init_from_args(\n\u001B[0m\u001B[1;32m   1424\u001B[0m           \u001B[0minitial_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitial_value\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1425\u001B[0m           \u001B[0mtrainable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrainable\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36m_init_from_args\u001B[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001B[0m\n\u001B[1;32m   1575\u001B[0m           \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1576\u001B[0m             \u001B[0mshape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minitial_value\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1577\u001B[0;31m           handle = eager_safe_variable_handle(\n\u001B[0m\u001B[1;32m   1578\u001B[0m               \u001B[0minitial_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitial_value\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1579\u001B[0m               \u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36meager_safe_variable_handle\u001B[0;34m(initial_value, shape, shared_name, name, graph_mode)\u001B[0m\n\u001B[1;32m    240\u001B[0m   \"\"\"\n\u001B[1;32m    241\u001B[0m   \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minitial_value\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_dtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 242\u001B[0;31m   return _variable_handle_from_shape_and_dtype(\n\u001B[0m\u001B[1;32m    243\u001B[0m       shape, dtype, shared_name, name, graph_mode, initial_value)\n\u001B[1;32m    244\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36m_variable_handle_from_shape_and_dtype\u001B[0;34m(shape, dtype, shared_name, name, graph_mode, initial_value)\u001B[0m\n\u001B[1;32m    172\u001B[0m     \u001B[0;31m# compatible with ASYNC execution mode. Further, since not all devices\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m     \u001B[0;31m# support string tensors, we encode the assertion string in the Op name\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 174\u001B[0;31m     gen_logging_ops._assert(  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m    175\u001B[0m         math_ops.logical_not(exists), [exists], name=\"EagerVariableNameReuse\")\n\u001B[1;32m    176\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/ops/gen_logging_ops.py\u001B[0m in \u001B[0;36m_assert\u001B[0;34m(condition, data, summarize, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0;32mpass\u001B[0m  \u001B[0;31m# Add nodes to the TensorFlow graph.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 55\u001B[0;31m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     56\u001B[0m   \u001B[0;31m# Add nodes to the TensorFlow graph.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0msummarize\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   6651\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\" name: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6652\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6653\u001B[0;31m   \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6654\u001B[0m   \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6655\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/DeepLearningCookbook-py38/lib/python3.8/site-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse"
     ]
    }
   ],
   "source": [
    "w, h = 740, 468\n",
    "style_image = K.variable(preprocess_image(style1_image_path, target_size=(h, w)))\n",
    "result_image = K.placeholder(style_image.shape)\n",
    "input_tensor = K.concatenate([style_image,\n",
    "                              result_image], axis=0)\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16.VGG16(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, loss_total, result_image, **other):\n",
    "        grads = K.gradients(loss_total, result_image)\n",
    "        outputs = [loss_total] + list(other.values()) + grads\n",
    "        self.iterate = K.function([result_image], outputs)\n",
    "        self.other = list(other.keys())\n",
    "        self.other_values = {}\n",
    "        self.shape = result_image.shape\n",
    "\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        outs = self.iterate([x.reshape(self.shape)])\n",
    "        self.loss_value = outs[0]\n",
    "        self.grad_values = outs[-1].flatten().astype('float64')\n",
    "        self.other_values = dict(zip(self.other, outs[1:-1]))\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        return np.copy(self.grad_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    if K.image_data_format() != 'channels_first':\n",
    "        x = K.permute_dimensions(x, (2, 0, 1))\n",
    "    features = K.batch_flatten(x)\n",
    "    return K.dot(features - 1, K.transpose(features - 1)) - 1\n",
    "\n",
    "def style_loss(layer_1, layer_2):\n",
    "    gr1 = gram_matrix(layer_1)\n",
    "    gr2 = gram_matrix(layer_2)\n",
    "    return K.sum(K.square(gr1 - gr2)) / (np.prod(layer_2.shape).value ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_outputs = [layer.output for layer in model.layers if '_conv' in layer.name]\n",
    "\n",
    "loss_style = K.variable(0.)\n",
    "for idx, layer_features in enumerate(feature_outputs):\n",
    "    loss_style += style_loss(layer_features[0, :, :, :], layer_features[1, :, :, :])\n",
    "\n",
    "style_evaluator = Evaluator(loss_style, result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(evaluator, image, num_iter=25):\n",
    "    for i in range(num_iter):\n",
    "        start_time = time.time()\n",
    "\n",
    "        image, min_val, info = fmin_l_bfgs_b(evaluator.loss, image.flatten(), fprime=evaluator.grads, maxfun=20)\n",
    "\n",
    "        end_time = time.time()\n",
    "        clear_output()\n",
    "        showarray(deprocess_image(image.copy(), h, w))\n",
    "\n",
    "        print(\"Iteration %d completed in %ds\" % (i + 1, end_time - start_time))\n",
    "        print(\"Current loss value:\", min_val)\n",
    "        print(' '.join(k + ':' + str(evaluator.other_values[k]) for k in evaluator.other))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 255, result_image.shape) - 128.\n",
    "res = run(style_evaluator, x, num_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x, exp=1.25):\n",
    "    _, d1, d2, d3 = x.shape\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        a = K.square(x[:, :, :d2 - 1, :d3 - 1] - x[:, :, 1:, :d3 - 1])\n",
    "        b = K.square(x[:, :, :d2 - 1, :d3 - 1] - x[:, :, :d2 - 1, 1:])\n",
    "    else:\n",
    "        a = K.square(x[:, :d1 - 1, :d2 - 1, :] - x[:, 1:, :d2 - 1, :])\n",
    "        b = K.square(x[:, :d1 - 1, :d2 - 1, :] - x[:, :d1 - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_variation = total_variation_loss(result_image) / 5000\n",
    "\n",
    "loss_with_variation = loss_variation + loss_style\n",
    "\n",
    "evaluator_with_variation = Evaluator(loss_with_variation, result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 255, result_image.shape) - 128.\n",
    "res = run(evaluator_with_variation, x, num_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, h = load_img(base_image_path).size\n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_image = K.variable(preprocess_image(style2_image_path, target_size=(h, w)))\n",
    "combination_image = K.placeholder(style_image.shape)\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16.VGG16(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_outputs = [layer.output for layer in model.layers if '_conv' in layer.name]\n",
    "\n",
    "loss_content = content_loss(feature_outputs[-1][0, :, :, :],\n",
    "                            feature_outputs[-1][2, :, :, :])\n",
    "loss_variation = total_variation_loss(combination_image)\n",
    "loss_style = K.variable(0.)\n",
    "for idx, layer_features in enumerate(feature_outputs):\n",
    "    loss_style += style_loss(layer_features[1, :, :, :], layer_features[2, :, :, :]) * (0.5 ** idx)\n",
    "\n",
    "loss_content /= 40\n",
    "loss_variation /= 10000\n",
    "\n",
    "loss_total = loss_content + loss_variation + loss_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_evaluator = Evaluator(loss_total, combination_image, loss_content=loss_content, \n",
    "                               loss_variation=loss_variation, loss_style=loss_style)\n",
    "run(combined_evaluator, preprocess_image(base_image_path), num_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, h = load_img(base_image_path).size\n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "winter_style_image = K.variable(preprocess_image('style_transfer/road-to-versailles-at-louveciennes.jpg',\n",
    "                                                 target_size=(h, w)))\n",
    "summer_style_image = K.variable(preprocess_image('style_transfer/VanGogh_Farmhouse.jpeg', target_size=(h, w)))\n",
    "combination_image = K.placeholder(summer_style_image.shape)\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              summer_style_image,\n",
    "                              winter_style_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16.VGG16(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_outputs = [layer.output for layer in model.layers if '_conv' in layer.name]\n",
    "\n",
    "loss_content = content_loss(feature_outputs[-1][0, :, :, :],\n",
    "                            feature_outputs[-1][2, :, :, :])\n",
    "loss_variation = total_variation_loss(combination_image)\n",
    "\n",
    "loss_style_summer = K.variable(0.)\n",
    "loss_style_winter = K.variable(0.)\n",
    "for idx, layer_features in enumerate(feature_outputs):\n",
    "    loss_style_summer += style_loss(layer_features[1, :, :, :], layer_features[-1, :, :, :]) * (0.5 ** idx)\n",
    "    loss_style_winter += style_loss(layer_features[2, :, :, :], layer_features[-1, :, :, :]) * (0.5 ** idx)\n",
    "\n",
    "loss_content /= 40\n",
    "loss_variation /= 10000\n",
    "\n",
    "summerness = K.placeholder()\n",
    "loss_total = (loss_content + loss_variation + \n",
    "              loss_style_summer * summerness + \n",
    "              loss_style_winter * (1 - summerness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_evaluator = Evaluator(loss_total, combination_image, loss_content=loss_content, \n",
    "                               loss_variation=loss_variation, loss_style_summer=loss_style_summer,\n",
    "                               loss_style_winter=loss_style_winter)\n",
    "iterate = K.function([combination_image, summerness], \n",
    "                     combined_evaluator.iterate.outputs)\n",
    "\n",
    "combined_evaluator.iterate = lambda inputs: iterate(inputs + [1.0])\n",
    "res = run(combined_evaluator, preprocess_image(base_image_path), num_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/style_transfer/summer_winter_%d.jpg'\n",
    "def save(res, step):\n",
    "    img = deprocess_image(res.copy(), h, w)\n",
    "    imsave(path % step, img)\n",
    "\n",
    "for step in range(1, 21):\n",
    "    combined_evaluator = Evaluator(loss_total, combination_image, loss_content=loss_content, \n",
    "                                   loss_variation=loss_variation, loss_style_summer=loss_style_summer,\n",
    "                                   loss_style_winter=loss_style_winter)\n",
    "    iterate = K.function([combination_image, summerness], \n",
    "                         combined_evaluator.iterate.outputs)\n",
    "\n",
    "    combined_evaluator.iterate = lambda inputs: iterate(inputs + [1.0 - step / 20.])\n",
    "    res = run(combined_evaluator, preprocess_image(base_image_path), num_iter=50)\n",
    "    save(res, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = glob.glob('../data/style_transfer/summer_winter_*.jpg')\n",
    "frames = sorted(frames, key=lambda f:int(f.split('.', 1)[0].rsplit('_', 1)[-1]))\n",
    "cycled = frames + list(reversed(frames[1:-1]))\n",
    "# Save them as frames into a gif \n",
    "kargs = { 'duration': 0.1 }\n",
    "imageio.mimsave('../data/style_transfer/animated.gif', [imageio.imread(x) for x in cycled], 'GIF', **kargs)\n",
    "\n",
    "HTML('<img src=\"../data/style_transfer/animated.gif\">')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}