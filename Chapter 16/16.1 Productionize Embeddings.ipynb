{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "import xml.sax\n",
    "from sklearn import svm\n",
    "import subprocess\n",
    "import mwparserfromhell\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Reshape\n",
    "from keras.layers.merge import Dot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import gensim\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/wp_movies_10k.ndjson') as fin:\n",
    "    movies = [json.loads(l) for l in fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_counts = Counter()\n",
    "for movie in movies:\n",
    "    link_counts.update(movie[2])\n",
    "\n",
    "top_links = [link for link, c in link_counts.items() if c >= 3]\n",
    "link_to_idx = {link: idx for idx, link in enumerate(top_links)}\n",
    "movie_to_idx = {movie[0]: idx for idx, movie in enumerate(movies)}\n",
    "pairs = []\n",
    "for movie in movies:\n",
    "    pairs.extend((link_to_idx[link], movie_to_idx[movie[0]]) for link in movie[2] if link in link_to_idx)\n",
    "pairs_set = set(pairs)\n",
    "len(pairs), len(top_links), len(movie_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_embedding_model(embedding_size=30):\n",
    "    link = Input(name='link', shape=(1,))\n",
    "    movie = Input(name='movie', shape=(1,))\n",
    "    link_embedding = Embedding(name='link_embedding', input_dim=len(top_links), output_dim=embedding_size)(link)\n",
    "    movie_embedding = Embedding(name='movie_embedding', input_dim=len(movie_to_idx), output_dim=embedding_size)(movie)\n",
    "    dot = Dot(name='dot_product', normalize=True, axes=2)([link_embedding, movie_embedding])\n",
    "    merged = Reshape((1,))(dot)\n",
    "    model = Model(inputs=[link, movie], outputs=[merged])\n",
    "    model.compile(optimizer='nadam', loss='mse')\n",
    "    return model\n",
    "\n",
    "model = movie_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(5)\n",
    "\n",
    "def batchifier(pairs, positive_samples=50, negative_ratio=5):\n",
    "    batch_size = positive_samples * (1 + negative_ratio)\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    while True:\n",
    "        for idx, (link_id, movie_id) in enumerate(random.sample(pairs, positive_samples)):\n",
    "            batch[idx, :] = (link_id, movie_id, 1)\n",
    "        idx = positive_samples\n",
    "        while idx < batch_size:\n",
    "            movie_id = random.randrange(len(movie_to_idx))\n",
    "            link_id = random.randrange(len(top_links))\n",
    "            if not (link_id, movie_id) in pairs_set:\n",
    "                batch[idx, :] = (link_id, movie_id, -1)\n",
    "                idx += 1\n",
    "        np.random.shuffle(batch)\n",
    "        yield {'link': batch[:, 0], 'movie': batch[:, 1]}, batch[:, 2]\n",
    "\n",
    "next(batchifier(pairs, positive_samples=3, negative_ratio=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples_per_batch=256\n",
    "\n",
    "model.fit_generator(\n",
    "    batchifier(pairs, positive_samples=positive_samples_per_batch, negative_ratio=5),\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(pairs) // positive_samples_per_batch,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = model.get_layer('movie_embedding')\n",
    "movie_weights = movie.get_weights()[0]\n",
    "movie_lengths = np.linalg.norm(movie_weights, axis=1)\n",
    "normalized_movies = (movie_weights.T / movie_lengths).T\n",
    "\n",
    "def similar_movies(movie):\n",
    "    dists = np.dot(normalized_movies, normalized_movies[movie_to_idx[movie]])\n",
    "    closest = np.argsort(dists)[-10:]\n",
    "    for c in reversed(closest):\n",
    "        print(c, movies[c][0], dists[c])\n",
    "\n",
    "similar_movies('Rogue One')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = model.get_layer('movie_embedding')\n",
    "movie_weights = movie.get_weights()[0]\n",
    "movie_lengths = np.linalg.norm(movie_weights, axis=1)\n",
    "normalized_movies = (movie_weights.T / movie_lengths).T\n",
    "nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(normalized_movies)\n",
    "\n",
    "with open('../data/movie_model.pkl', 'wb') as fout:\n",
    "    pickle.dump({\n",
    "        'nbrs': nbrs,\n",
    "        'normalized_movies': normalized_movies,\n",
    "        'movie_to_idx': movie_to_idx,\n",
    "    }, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/movie_model.pkl', 'rb') as fin:\n",
    "    m = pickle.load(fin)\n",
    "movie_names = [x[0] for x in sorted(movie_to_idx.items(), key=lambda t:t[1])]\n",
    "distances, indices = m['nbrs'].kneighbors(\n",
    "    [m['normalized_movies'][m['movie_to_idx']['Rogue One']]])\n",
    "for idx in indices[0]:\n",
    "    print(movie_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = 'douwe'\n",
    "USER = 'djangosite'\n",
    "PWD = 'z0g3h31m!'\n",
    "HOST = '127.0.0.1'\n",
    "connection_str = \"dbname='%s' user='%s' password='%s' host='%s'\"\n",
    "conn = psycopg2.connect(connection_str % (DB_NAME, USER, PWD, HOST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute('INSERT INTO movie (movie_name, embedding) VALUES (%s, %s)',\n",
    "                   (movie_names[0], normalized_movies[0].tolist()))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute('DELETE FROM movie;')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    for movie, embedding in zip(movies, normalized_movies):\n",
    "        cursor.execute('INSERT INTO movie (movie_name, embedding)'\n",
    "                       ' VALUES (%s, %s)',\n",
    "               (movie[0], embedding.tolist()))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(conn, q):\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute('SELECT movie_name, embedding FROM movie'\n",
    "                       '    WHERE lower(movie_name) LIKE %s'\n",
    "                       '    LIMIT 1',\n",
    "                       ('%' + q.lower() + '%',))\n",
    "        if cursor.rowcount == 0:\n",
    "            return []\n",
    "        movie_name, embedding = cursor.fetchone()\n",
    "        cursor.execute('SELECT movie_name, '\n",
    "                       '       cube_distance(cube(embedding), '\n",
    "                       '                     cube(%s)) as distance '\n",
    "                       '    FROM movie'\n",
    "                       '    ORDER BY distance'\n",
    "                       '    LIMIT 5',\n",
    "                       (embedding,))\n",
    "        return list(cursor.fetchall())\n",
    "    \n",
    "recommend_movies(conn, 'The Force Awakens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute('SELECT movie_name, cube_distance(cube(embedding), cube(%s)) as distance '\n",
    "                   '    FROM movie'\n",
    "                   '    ORDER BY distance'\n",
    "                   '    LIMIT 5',\n",
    "                   (emb,))\n",
    "    x = list(cursor)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'GoogleNews-vectors-negative300.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(MODEL, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['espresso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(norm, positive):\n",
    "    vec = norm[model.vocab[positive].index]\n",
    "    dists = np.dot(norm, vec)\n",
    "    most_extreme = np.argpartition(-dists, 10)[:10]\n",
    "    res = ((model.index2word[idx], dists[idx]) for idx in most_extreme)\n",
    "    return list(sorted(res, key=lambda t:t[1], reverse=True))\n",
    "\n",
    "for word, score in most_similar(model.syn0norm, 'espresso'):\n",
    "    print(word, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=42, n_iter=40)\n",
    "reduced = svd.fit_transform(model.syn0norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_lengths = np.linalg.norm(reduced, axis=1)\n",
    "normalized_reduced = (reduced.T / reduced_lengths).T\n",
    "normalized_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, score in most_similar(normalized_reduced, 'espresso'):\n",
    "    print(word, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in most_extreme:\n",
    "    print(model.index2word[idx], dists[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}